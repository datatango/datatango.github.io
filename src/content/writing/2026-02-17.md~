---
title: Debugging KeyError in Python CSV Files: The Hidden BOM
date: "2026-02-17"
description: Understanding BOM when processing CSVs in Python
---
I was batch converting TIFFs using a CSV manifest when my script failed with a missing column error:
```bash
ERROR CSV missing required columns: ['ark_id']. Found: ['\ufeffark_id', 'work_id', 'http_path', ...]

```
The required headers were right there. But Python saw \ufeffark_id, not ark_id. That \ufeff is a BOM, which Excel silently added when saving the file.

The CSV looked fine in my text editor and the code was straightforward:

```python
import csv

with open('manifest_data.csv', encoding='utf-8') as f:
    reader = csv.DictReader(f, delimiter='\t')
    for row in reader:
        print(row['ark_id'])
```

Although when I printed the actual keys, the problem revealed itself (through the error message too):

```python
dict_keys(['\ufeffark_id', 'work_id', 'http_path', 's8_path', 'img_index', 'collection_name'])
```

## What is a BOM?

A BOM (Byte Order Mark) is a special Unicode character (U+FEFF) placed at the beginning of a text file to indicate its encoding. For UTF-8, it's the three-byte sequence `EF BB BF`. UTF-8 doesn't actually need a BOM—unlike UTF-16, there's no byte order ambiguity, but Microsoft applications add one anyway as a signature.

The BOM is invisible in most text editors and Excel itself.

## Detecting a BOM

Once I knew what to look for, checking became easy.

```bash
xxd -l 3 file.csv
```

If one sees `efbb bf` at the start, it is a BOM.

Alternatively, use `file`:

```bash
file file.csv
```

It will explicitly state `UTF-8 Unicode (with BOM) text` if one is present.

## Fix

Python has a built-in encoding specifically for this: `utf-8-sig`. It automatically strips the BOM on read:

```python
import csv

with open('manifest_data.csv', encoding='utf-8-sig') as f:
    reader = csv.DictReader(f, delimiter='\t')
    for row in reader:
        print(row['ark_id'])
```

## Writing CSVs for Excel

The flip side: if you're generating CSVs that will be opened in Excel, you might want to *include* a BOM. Without it, Excel sometimes mangles non-ASCII characters. Use `utf-8-sig` when writing:

```python
import csv

with open('output.csv', 'w', encoding='utf-8-sig', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['名前', 'date', 'identifier'])
    writer.writerow(['地図', '1920', 'ark:/12345/x1'])
```

The BOM is one of those invisible gotchas that's easy to miss in testing but breaks production code. It is helpful to check for it whenever CSV parsing behaves unexpectedly. 

As such, for any CSV processing where the source might be Excel or another Windows application, I default to `utf-8-sig`:

```python
def read_csv(filepath):
    with open(filepath, encoding='utf-8-sig') as f:
        return list(csv.DictReader(f))
```